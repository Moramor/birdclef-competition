{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, we'll use a pre-trained machine learning model to generate a submission to the [BirdClef2023 competition](https://www.kaggle.com/c/birdclef-2023).  The goal of the competition is to identify Eastern African bird species by sound.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_io as tfio\n\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport glob\n\nimport csv\nimport io\n\nfrom IPython.display import Audio\n\n# Import all the vision library\nfrom fastai.vision.all import *\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-08T12:57:13.943488Z","iopub.execute_input":"2023-03-08T12:57:13.943877Z","iopub.status.idle":"2023-03-08T12:57:21.491538Z","shell.execute_reply.started":"2023-03-08T12:57:13.943840Z","shell.execute_reply":"2023-03-08T12:57:21.490338Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Explore the training data\n\nWe'll start by loading a couple of training examples and using the IPython.display.Audio module to play them!","metadata":{}},{"cell_type":"code","source":"# Load a sample audio files from two different species\naudio_abe, sr_abe = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\")\naudio_abh, sr_abh = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\")","metadata":{"execution":{"iopub.status.busy":"2023-03-08T13:02:13.959552Z","iopub.execute_input":"2023-03-08T13:02:13.960712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Play the audio\nAudio(data=audio_abe, rate=sr_abe)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:25.822527Z","iopub.execute_input":"2023-03-07T18:26:25.823301Z","iopub.status.idle":"2023-03-07T18:26:25.873528Z","shell.execute_reply.started":"2023-03-07T18:26:25.823267Z","shell.execute_reply":"2023-03-07T18:26:25.872446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Play the audio\nAudio(data=audio_abh, rate=sr_abh)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:25.874393Z","iopub.execute_input":"2023-03-07T18:26:25.874881Z","iopub.status.idle":"2023-03-07T18:26:25.915097Z","shell.execute_reply.started":"2023-03-07T18:26:25.874851Z","shell.execute_reply":"2023-03-07T18:26:25.914013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Match the model's output with the bird species in the competition\n\nThe competition includes 264 classes of birds, 261 of which exist in this model. We'll set up a way to map the model's output logits to our competition.","metadata":{}},{"cell_type":"code","source":"model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1')\nlabels_path = hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1') + \"/assets/label.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:25.918763Z","iopub.execute_input":"2023-03-07T18:26:25.919053Z","iopub.status.idle":"2023-03-07T18:26:33.264685Z","shell.execute_reply.started":"2023-03-07T18:26:25.919023Z","shell.execute_reply":"2023-03-07T18:26:33.263005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the name of the class with the top score when mean-aggregated across frames.\ndef class_names_from_csv(class_map_csv_text):\n    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n    with open(labels_path) as csv_file:\n        csv_reader = csv.reader(csv_file, delimiter=',')\n        class_names = [mid for mid, desc in csv_reader]\n        return class_names[1:]\n\n## note that the bird classifier classifies a much larger set of birds than the\n## competition, so we need to load the model's set of class names or else our \n## indices will be off.\nclasses = class_names_from_csv(labels_path)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:33.266455Z","iopub.execute_input":"2023-03-07T18:26:33.266825Z","iopub.status.idle":"2023-03-07T18:26:33.290684Z","shell.execute_reply.started":"2023-03-07T18:26:33.266789Z","shell.execute_reply":"2023-03-07T18:26:33.289205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\")\ntrain_metadata.head()\ncompetition_classes = sorted(train_metadata.primary_label.unique())\n\nforced_defaults = 0\ncompetition_class_map = []\nfor c in competition_classes:\n    try:\n        i = classes.index(c)\n        competition_class_map.append(i)\n    except:\n        competition_class_map.append(0)\n        forced_defaults += 1\n        \n## this is the count of classes not supported by our pretrained model\n## you could choose to simply not predict these, set a default as above,\n## or create your own model using the pretrained model as a base.\nforced_defaults","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:33.292249Z","iopub.execute_input":"2023-03-07T18:26:33.292678Z","iopub.status.idle":"2023-03-07T18:26:33.458124Z","shell.execute_reply.started":"2023-03-07T18:26:33.292611Z","shell.execute_reply":"2023-03-07T18:26:33.457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Preprocess the data\n\nThe following functions are one way to load the audio provided and break it up into the five-second samples with a sample rate of 32,000 required by the competition.","metadata":{}},{"cell_type":"code","source":"def frame_audio(\n      audio_array: np.ndarray,\n      window_size_s: float = 5.0,\n      hop_size_s: float = 5.0,\n      sample_rate = 32000,\n      ) -> np.ndarray:\n    \n    \"\"\"Helper function for framing audio for inference.\"\"\"\n    \"\"\" using tf.signal \"\"\"\n    if window_size_s is None or window_size_s < 0:\n        return audio_array[np.newaxis, :]\n    frame_length = int(window_size_s * sample_rate)\n    hop_length = int(hop_size_s * sample_rate)\n    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n    return framed_audio\n\ndef ensure_sample_rate(waveform, original_sample_rate,\n                       desired_sample_rate=32000):\n    \"\"\"Resample waveform if required.\"\"\"\n    if original_sample_rate != desired_sample_rate:\n        waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n    return desired_sample_rate, waveform","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:33.459554Z","iopub.execute_input":"2023-03-07T18:26:33.45989Z","iopub.status.idle":"2023-03-07T18:26:33.469971Z","shell.execute_reply.started":"2023-03-07T18:26:33.459858Z","shell.execute_reply":"2023-03-07T18:26:33.46833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we load one training sample - use the Audio function to listen to the samples inside the notebook!","metadata":{}},{"cell_type":"code","source":"audio, sample_rate = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/afghor1/XC156639.ogg\")\nsample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\nAudio(wav_data, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:26:33.474189Z","iopub.execute_input":"2023-03-07T18:26:33.474536Z","iopub.status.idle":"2023-03-07T18:26:34.056941Z","shell.execute_reply.started":"2023-03-07T18:26:33.474501Z","shell.execute_reply":"2023-03-07T18:26:34.055418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Make predictions\n\nEach test sample is cut into 5-second chunks. We use the pretrained model to return probabilities for all 10k birds included in the model, then pull out the classes used in this competition to create a final submission row. Note that we are NOT doing anything special to handle the 3 missing classes; those will need fine-tuning / transfer learning, which will be handled in a separate notebook.","metadata":{}},{"cell_type":"code","source":"fixed_tm = frame_audio(wav_data)\nlogits, embeddings = model.infer_tf(fixed_tm[:1])\nprobabilities = tf.nn.softmax(logits)\nargmax = np.argmax(probabilities)\nprint(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:33.85177Z","iopub.execute_input":"2023-03-07T18:27:33.852139Z","iopub.status.idle":"2023-03-07T18:27:42.452689Z","shell.execute_reply.started":"2023-03-07T18:27:33.852108Z","shell.execute_reply":"2023-03-07T18:27:42.451217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n    \n    audio, sample_rate = librosa.load(filename)\n    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n    \n    fixed_tm = frame_audio(wav_data)\n    \n    frame = 5\n    all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n    for window in fixed_tm[1:]:\n        if frame_limit_secs and frame > frame_limit_secs:\n            continue\n        \n        logits, embeddings = model.infer_tf(window[np.newaxis, :])\n        all_logits = np.concatenate([all_logits, logits], axis=0)\n        frame += 5\n    \n    frame = 5\n    all_probabilities = []\n    for frame_logits in all_logits:\n        probabilities = tf.nn.softmax(frame_logits).numpy()\n        \n        ## set the appropriate row in the sample submission\n        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame), competition_classes] = probabilities[competition_class_map]\n        frame += 5","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:42.456508Z","iopub.execute_input":"2023-03-07T18:27:42.456847Z","iopub.status.idle":"2023-03-07T18:27:42.466058Z","shell.execute_reply.started":"2023-03-07T18:27:42.456815Z","shell.execute_reply":"2023-03-07T18:27:42.464463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Generate a submission\n\nNow we process all of the test samples as discussed above, creating output rows, and saving them in the provided `sample_submission.csv`. Finally, we save these rows to our final output file: `submission.csv`. This is the file that gets submitted and scored when you submit the notebook.","metadata":{}},{"cell_type":"code","source":"test_samples = list(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\ntest_samples","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:42.46746Z","iopub.execute_input":"2023-03-07T18:27:42.468572Z","iopub.status.idle":"2023-03-07T18:27:42.491495Z","shell.execute_reply.started":"2023-03-07T18:27:42.46851Z","shell.execute_reply":"2023-03-07T18:27:42.49023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(\"/kaggle/input/birdclef-2023/sample_submission.csv\")\nsample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:42.493996Z","iopub.execute_input":"2023-03-07T18:27:42.494288Z","iopub.status.idle":"2023-03-07T18:27:42.598852Z","shell.execute_reply.started":"2023-03-07T18:27:42.494253Z","shell.execute_reply":"2023-03-07T18:27:42.597816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frame_limit_secs = 15 if sample_sub.shape[0] == 3 else None\nfor sample_filename in test_samples:\n    predict_for_sample(sample_filename, sample_sub, frame_limit_secs=15)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:42.600544Z","iopub.execute_input":"2023-03-07T18:27:42.600888Z","iopub.status.idle":"2023-03-07T18:27:48.722475Z","shell.execute_reply.started":"2023-03-07T18:27:42.600855Z","shell.execute_reply":"2023-03-07T18:27:48.720492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:48.723696Z","iopub.execute_input":"2023-03-07T18:27:48.724021Z","iopub.status.idle":"2023-03-07T18:27:48.753783Z","shell.execute_reply.started":"2023-03-07T18:27:48.723987Z","shell.execute_reply":"2023-03-07T18:27:48.752703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:27:48.755372Z","iopub.execute_input":"2023-03-07T18:27:48.755961Z","iopub.status.idle":"2023-03-07T18:27:48.77547Z","shell.execute_reply.started":"2023-03-07T18:27:48.755926Z","shell.execute_reply":"2023-03-07T18:27:48.774069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}